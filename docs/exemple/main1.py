import os
import re
import ast
import json
import tempfile
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, List, TypedDict, Optional, Annotated
from langgraph.graph import StateGraph, END
from langchain_core.prompts import ChatPromptTemplate
from llm_agent_smith.models.geminiModel import GeminiModel


# DefiniÃ§Ã£o do estado do sistema
class TDDState(TypedDict):
    user_request: str
    features: Annotated[List[str], lambda l1, l2: l1 + l2]
    current_feature: Optional[str]
    production_code: str
    test_code: str
    test_results: Optional[str]
    history: Annotated[List[Dict], lambda l1, l2: l1 + l2]
    iteration_count: int


# ConfiguraÃ§Ãµes
MAX_ITERATIONS = 5
MAX_FEATURE_ATTEMPTS = 3


# FunÃ§Ãµes utilitÃ¡rias
def extract_code(text: str) -> str:
    """Extrai cÃ³digo de blocos markdown"""
    if "```python" in text:
        match = re.search(r"```python(.*?)```", text, re.DOTALL)
        if match:
            return match.group(1).strip()
    return text.strip()


def validate_interface(old_code: str, new_code: str) -> bool:
    """Verifica se a interface pÃºblica foi mantida"""
    if not old_code.strip():
        return True

    try:
        old_tree = ast.parse(old_code)
        new_tree = ast.parse(new_code)

        old_public = [
            n.name
            for n in old_tree.body
            if isinstance(n, (ast.FunctionDef, ast.ClassDef))
            and not n.name.startswith("_")
        ]

        new_public = [
            n.name
            for n in new_tree.body
            if isinstance(n, (ast.FunctionDef, ast.ClassDef))
            and not n.name.startswith("_")
        ]

        return set(old_public) == set(new_public)
    except:
        return False


def is_code_safe(code: str) -> bool:
    """Verifica se o cÃ³digo nÃ£o contÃ©m operaÃ§Ãµes perigosas"""
    dangerous_patterns = [
        r"__import__\s*\(",
        r"subprocess\.",
        r"os\.system\(",
        r"eval\(",
        r"exec\(",
        r"open\(",
        r"shutil\.",
        r"sys\.exit",
    ]
    return not any(re.search(pattern, code) for pattern in dangerous_patterns)


def run_tests(production_code: str, test_code: str) -> str:
    """Executa os testes e retorna os resultados"""
    if not test_code.strip():
        return "Nenhum teste definido"

    with tempfile.TemporaryDirectory() as tmpdir:
        # Salvar cÃ³digo de produÃ§Ã£o
        prod_path = Path(tmpdir) / "production.py"
        prod_path.write_text(production_code)

        # Adicionar imports necessÃ¡rios
        test_content = (
            "import re\nimport sys\nsys.path.insert(0, '.')\nfrom production import *\n\n"
            + test_code
        )

        # Salvar testes
        test_path = Path(tmpdir) / "test_production.py"
        test_path.write_text(test_content)

        try:
            result = subprocess.run(
                ["pytest", "-v", str(test_path)],
                capture_output=True,
                text=True,
                timeout=10,
            )
            output = result.stdout + result.stderr
        except subprocess.TimeoutExpired:
            output = "ERRO: Timeout ao executar testes"
        except Exception as e:
            output = f"ERRO: {str(e)}"

        return output


def tests_passed(test_output: str) -> bool:
    """Verifica se todos os testes passaram"""
    return "failed" not in test_output.lower() and "error" not in test_output.lower()


# InicializaÃ§Ã£o do LLM
llm = GeminiModel.llm_model()


# Definindo os nÃ³s do workflow
def decompose_features(state: TDDState) -> TDDState:
    """DecompÃµe a solicitaÃ§Ã£o em features mÃ­nimas testÃ¡veis"""
    prompt = ChatPromptTemplate.from_template(
        "SolicitaÃ§Ã£o do usuÃ¡rio: {request}\n\n"
        "Decomponha em features mÃ­nimas testÃ¡veis (MFVs):\n"
        "- Uma por linha\n"
        "- Ordenadas por dependÃªncia\n"
        "- Formato JSON array\n\n"
        "Apenas a lista em formato JSON:"
    )

    chain = prompt | llm
    response = chain.invoke({"request": state["user_request"]})

    try:
        features = json.loads(response.content)
        print(f"ğŸ“‹ Features identificadas: {len(features)}")
        for i, feat in enumerate(features, 1):
            print(f"  {i}. {feat}")
    except json.JSONDecodeError:
        features = [state["user_request"]]
        print("âš ï¸ NÃ£o foi possÃ­vel decompor, usando solicitaÃ§Ã£o completa")

    history_entry = {
        "timestamp": datetime.now().isoformat(),
        "action": "DecomposiÃ§Ã£o de features",
        "details": (
            response.content[:500] + "..."
            if len(response.content) > 500
            else response.content
        ),
    }

    return {
        **state,
        "features": features,
        "history": state["history"] + [history_entry],
    }


def select_next_feature(state: TDDState) -> TDDState:
    """Seleciona a prÃ³xima feature a ser implementada"""
    if not state["features"]:
        return {**state, "current_feature": None}

    next_feature = state["features"].pop(0)
    print(f"\nâ¡ï¸ Feature atual: {next_feature}")

    history_entry = {
        "timestamp": datetime.now().isoformat(),
        "action": "Selecionar feature",
        "details": next_feature,
    }

    return {
        **state,
        "current_feature": next_feature,
        "iteration_count": 0,
        "history": state["history"] + [history_entry],
    }


def write_failing_test(state: TDDState) -> TDDState:
    """Escreve um teste falhando para a feature atual"""
    prompt = ChatPromptTemplate.from_template(
        "Escreva um teste Pytest FALHANDO para a feature:\n{feature}\n\n"
        "Contexto:\nCÃ³digo atual:\n{code}\n\n"
        "Diretrizes:\n- Teste apenas o essencial\n- Espere falhar inicialmente\n"
        "CÃ³digo do teste:"
    )

    chain = prompt | llm
    response = chain.invoke(
        {"feature": state["current_feature"], "code": state["production_code"]}
    )

    new_test = extract_code(response.content)
    updated_test_code = state["test_code"] + "\n\n" + new_test

    history_entry = {
        "timestamp": datetime.now().isoformat(),
        "action": "Escrever teste (Fase RED)",
        "details": new_test[:500] + "..." if len(new_test) > 500 else new_test,
    }

    print(
        f"ğŸ“ Teste escrito (Fase RED):\n{new_test[:200]}{'...' if len(new_test) > 200 else ''}"
    )

    return {
        **state,
        "test_code": updated_test_code,
        "history": state["history"] + [history_entry],
        "iteration_count": state["iteration_count"] + 1,
    }


def execute_tests(state: TDDState) -> TDDState:
    """Executa os testes e armazena os resultados"""
    test_results = run_tests(state["production_code"], state["test_code"])

    history_entry = {
        "timestamp": datetime.now().isoformat(),
        "action": "Executar testes",
        "details": (
            test_results[:500] + "..." if len(test_results) > 500 else test_results
        ),
    }

    print(
        f"ğŸ§ª Resultado dos testes:\n{test_results[:300]}{'...' if len(test_results) > 300 else ''}"
    )

    return {
        **state,
        "test_results": test_results,
        "history": state["history"] + [history_entry],
    }


def implement_minimal_fix(state: TDDState) -> TDDState:
    """Implementa a correÃ§Ã£o mÃ­nima para passar nos testes"""
    prompt = ChatPromptTemplate.from_template(
        "Feature: {feature}\n"
        "CÃ³digo atual:\n{current_code}\n\n"
        "Testes falhando:\n{test_results}\n\n"
        "Implemente a CORREÃ‡ÃƒO MÃNIMA para fazer os testes passarem:\n"
        "- AlteraÃ§Ãµes mÃ­nimas necessÃ¡rias\n"
        "- Mantenha KISS e DRY\n"
        "- NÃ£o adicione funcionalidades extras\n\n"
        "CÃ³digo corrigido:"
    )

    chain = prompt | llm
    response = chain.invoke(
        {
            "feature": state["current_feature"],
            "current_code": state["production_code"],
            "test_results": state["test_results"][:1000],
        }
    )

    new_code = extract_code(response.content)

    # Validar seguranÃ§a e interface
    if not is_code_safe(new_code):
        print("â›” CorreÃ§Ã£o rejeitada: Problemas de seguranÃ§a detectados!")
        return state

    if not validate_interface(state["production_code"], new_code):
        print("âš ï¸ CorreÃ§Ã£o rejeitada: Interface pÃºblica alterada!")
        return state

    history_entry = {
        "timestamp": datetime.now().isoformat(),
        "action": "Implementar correÃ§Ã£o (Fase GREEN)",
        "details": new_code[:500] + "..." if len(new_code) > 500 else new_code,
    }

    print(
        f"ğŸ”§ CÃ³digo atualizado (Fase GREEN):\n{new_code[:200]}{'...' if len(new_code) > 200 else ''}"
    )

    return {
        **state,
        "production_code": new_code,
        "history": state["history"] + [history_entry],
        "iteration_count": state["iteration_count"] + 1,
    }


def refactor_code(state: TDDState) -> TDDState:
    """Refatora o cÃ³digo mantendo os testes passando"""
    prompt = ChatPromptTemplate.from_template(
        "Refatore o cÃ³digo mantendo o mesmo comportamento:\n"
        "CÃ³digo atual:\n{code}\n\n"
        "Diretrizes:\n"
        "1. Aplique KISS e DRY\n"
        "2. Melhore legibilidade\n"
        "3. NÃ£o altere funcionalidades\n"
        "CÃ³digo refatorado:"
    )

    chain = prompt | llm
    response = chain.invoke({"code": state["production_code"]})

    new_code = extract_code(response.content)

    # Validar seguranÃ§a e interface
    if not is_code_safe(new_code):
        print("â›” RefatoraÃ§Ã£o rejeitada: Problemas de seguranÃ§a!")
        return state

    if not validate_interface(state["production_code"], new_code):
        print("âš ï¸ RefatoraÃ§Ã£o rejeitada: Interface pÃºblica alterada!")
        return state

    history_entry = {
        "timestamp": datetime.now().isoformat(),
        "action": "Refatorar cÃ³digo (Fase REFACTOR)",
        "details": new_code[:500] + "..." if len(new_code) > 500 else new_code,
    }

    print(
        f"âœ¨ CÃ³digo refatorado (Fase REFACTOR):\n{new_code[:200]}{'...' if len(new_code) > 200 else ''}"
    )

    return {
        **state,
        "production_code": new_code,
        "history": state["history"] + [history_entry],
    }


def should_continue(state: TDDState) -> str:
    """Decide o prÃ³ximo passo baseado no estado atual"""
    # Se nÃ£o hÃ¡ mais features, terminar
    if not state["current_feature"]:
        return "END"

    # Se testes passaram, refatorar
    if tests_passed(state["test_results"]):
        return "refactor"

    # Se excedeu o nÃºmero mÃ¡ximo de tentativas, passar para prÃ³xima feature
    if state["iteration_count"] >= MAX_FEATURE_ATTEMPTS:
        print("âš ï¸ AtenÃ§Ã£o: Feature nÃ£o implementada apÃ³s tentativas mÃ¡ximas")
        return "select_next_feature"

    # Caso contrÃ¡rio, tentar corrigir novamente
    return "implement_fix"


def finalize(state: TDDState) -> TDDState:
    """AÃ§Ãµes finais apÃ³s completar todas as features"""
    print(f"\n{'='*60}\nğŸ TDD COMPLETO!")
    print(f"ğŸ“ CÃ³digo final: {len(state['production_code'].splitlines())} linhas")
    print(f"ğŸ§ª Testes: {len(state['test_code'].splitlines())} linhas")

    # Salvar resultados
    with open("production_code.py", "w") as f:
        f.write(state["production_code"])

    with open("test_production.py", "w") as f:
        f.write(state["test_code"])

    with open("tdd_history.json", "w") as f:
        json.dump(state["history"], f, indent=2)

    print("\nğŸ’¾ Resultados salvos:")
    print("- production_code.py: CÃ³digo de produÃ§Ã£o")
    print("- test_production.py: Testes unitÃ¡rios")
    print("- tdd_history.json: HistÃ³rico do ciclo TDD")

    return state


# Construindo o workflow com LangGraph
workflow = StateGraph(TDDState)

# Definindo os nÃ³s
workflow.add_node("decompose", decompose_features)
workflow.add_node("select_next_feature", select_next_feature)
workflow.add_node("write_test", write_failing_test)
workflow.add_node("run_tests", execute_tests)
workflow.add_node("implement_fix", implement_minimal_fix)
workflow.add_node("refactor", refactor_code)
workflow.add_node("finalize", finalize)

# Definindo o fluxo inicial
workflow.set_entry_point("decompose")
workflow.add_edge("decompose", "select_next_feature")

# Fluxo para cada feature
workflow.add_edge("select_next_feature", "write_test")
workflow.add_edge("write_test", "run_tests")
workflow.add_edge("run_tests", "decide_next_step")

# Ponto de decisÃ£o apÃ³s executar testes
workflow.add_conditional_edges(
    "decide_next_step",
    should_continue,
    {
        "implement_fix": "implement_fix",
        "refactor": "refactor",
        "select_next_feature": "select_next_feature",
        "END": "finalize",
    },
)

# Fluxo apÃ³s implementar correÃ§Ã£o
workflow.add_edge("implement_fix", "run_tests")

# Fluxo apÃ³s refatoraÃ§Ã£o
workflow.add_edge("refactor", "select_next_feature")

# FinalizaÃ§Ã£o
workflow.add_edge("finalize", END)

# Compilar o workflow
tdd_agent = workflow.compile()


# Interface do usuÃ¡rio
def main():
    print("\n" + "=" * 60)
    print("ğŸš€ TDD Automatizado com Gemini e LangGraph")
    print("=" * 60)
    print("Descreva o que vocÃª quer construir (ex: 'Implemente um validador de CPF')")
    print("Digite 'sair' para terminar\n")

    while True:
        user_request = input("\nğŸ¯ O que vocÃª quer construir? ")

        if user_request.lower() in ["sair", "exit", "quit"]:
            break

        # Estado inicial
        initial_state = {
            "user_request": user_request,
            "features": [],
            "current_feature": None,
            "production_code": "",
            "test_code": "",
            "test_results": None,
            "history": [],
            "iteration_count": 0,
        }

        # Executar o workflow
        print(f"\n{'='*60}\nğŸ§ª Iniciando TDD para: {user_request}\n{'='*60}")
        result = tdd_agent.invoke(initial_state, {"recursion_limit": MAX_ITERATIONS})

        print("\nâœ… Processo concluÃ­do! Verifique os arquivos gerados.")

    print("\nObrigado por usar o TDD Automatizado!")


if __name__ == "__main__":
    main()
